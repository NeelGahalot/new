{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44496d8d-96d6-4aa4-93fa-1a47e1870409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.34.96)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.96 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from boto3) (1.34.96)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from boto3) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.96->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.96->boto3) (2.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.96->boto3) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3\n",
    "import boto3\n",
    "s3 = boto3.resource()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45bc0b85-3bce-4000-97e1-e2887b1d2271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/Deeplab\n"
     ]
    }
   ],
   "source": [
    "%cd /teamspace/studios/this_studio/Deeplab/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb40db87-12cd-4c60-b79b-7ce5e52e97a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.2.1+cu121)\n",
      "Requirement already satisfied: torchvision in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.17.1+cu121)\n",
      "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (1.26.2)\n",
      "Requirement already satisfied: pillow in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (10.3.0)\n",
      "Requirement already satisfied: scikit-learn in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (4.66.2)\n",
      "Requirement already satisfied: matplotlib in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (3.8.2)\n",
      "Collecting visdom (from -r requirements.txt (line 8))\n",
      "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting loralib (from -r requirements.txt (line 9))\n",
      "  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (4.11.0)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (1.12)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.3)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 5)) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 7)) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 7)) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 7)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 7)) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 7)) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 7)) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from visdom->-r requirements.txt (line 8)) (2.31.0)\n",
      "Requirement already satisfied: tornado in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from visdom->-r requirements.txt (line 8)) (6.4)\n",
      "Requirement already satisfied: six in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from visdom->-r requirements.txt (line 8)) (1.16.0)\n",
      "Collecting jsonpatch (from visdom->-r requirements.txt (line 8))\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: websocket-client in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from visdom->-r requirements.txt (line 8)) (1.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonpatch->visdom->-r requirements.txt (line 8)) (2.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->visdom->-r requirements.txt (line 8)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->visdom->-r requirements.txt (line 8)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->visdom->-r requirements.txt (line 8)) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->visdom->-r requirements.txt (line 8)) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "Downloading loralib-0.1.2-py3-none-any.whl (10 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: visdom\n",
      "  Building wheel for visdom (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408194 sha256=8f4e183d1433c200a7634e353bbb74959e131f2be5b6a4d710beecb92189ef25\n",
      "  Stored in directory: /teamspace/studios/this_studio/.cache/pip/wheels/42/29/49/5bed207bac4578e4d2c0c5fc0226bfd33a7e2953ea56356855\n",
      "Successfully built visdom\n",
      "Installing collected packages: loralib, jsonpatch, visdom\n",
      "Successfully installed jsonpatch-1.33 loralib-0.1.2 visdom-0.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "\n",
    "# Importing all Requirements\n",
    "from torch.utils.data import dataset\n",
    "from tqdm import tqdm\n",
    "import network\n",
    "import utils\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "from datasets import VOCSegmentation, Cityscapes, cityscapes, LeafDataset\n",
    "from torchvision import transforms as T\n",
    "from metrics import StreamSegMetrics, BinarySegMetrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import random\n",
    "import loralib as lora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdb798d5-a137-46b0-985a-027baef6f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "inhouse_default = '/teamspace/studios/this_studio/Deeplab/saved_models/best_deeplabv3plus_mobilenet_custom_os16_0.7854892764326529.pth'\n",
    "#Deeplab/saved_models/best_deeplabv3plus_mobilenet_custom_os16_0.7854892764326529.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5bbce58-a66b-450d-adb1-b50c05615b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_target(mask):\n",
    "  leaf_color = [255, 255, 255]\n",
    "  rgb_mask = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)\n",
    "  rgb_mask[mask == 1] = leaf_color\n",
    "  return Image.fromarray(rgb_mask)\n",
    "\n",
    "def show(image):\n",
    "  sample = Image.open(image)\n",
    "  plt.imshow(sample)\n",
    "  plt.axis(\"off\")\n",
    "  plt.show()\n",
    "\n",
    "img_transform = T.Compose([\n",
    "              T.Resize((512, 512)),\n",
    "              T.ToTensor(),\n",
    "              T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "          ])\n",
    "\n",
    "mask_transform = T.Compose([\n",
    "              T.Resize((512, 512), interpolation=T.InterpolationMode.NEAREST),\n",
    "              T.ToTensor(),\n",
    "          ])\n",
    "\n",
    "def load_model(ckpt, model_type = 'deeplabv3plus_mobilenet', num_classes= 1, output_stride= 16):\n",
    "  os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "  print(\"Device: %s\" % device)\n",
    "\n",
    "  model = network.modeling.__dict__[model_type](num_classes, output_stride)\n",
    "  network.convert_to_separable_conv(model.classifier)\n",
    "  utils.set_bn_momentum(model.backbone, momentum=0.01)\n",
    "  checkpoint = torch.load(ckpt, map_location=torch.device('cpu'))\n",
    "  model.load_state_dict(checkpoint[\"model_state\"])\n",
    "  model = nn.DataParallel(model)\n",
    "  model.to(device)\n",
    "  print(\"Resume model from %s\" % ckpt)\n",
    "  del checkpoint\n",
    "  return model\n",
    "\n",
    "def get_target(mask_path):\n",
    "  mask = Image.open(mask_path)\n",
    "  mask_array = np.array(mask)\n",
    "  mask_array = (mask_array > 128).astype(np.uint8)\n",
    "  mask_array = mask_array * 255\n",
    "  mask = Image.fromarray(mask_array.astype(np.uint8))\n",
    "  mask = mask_transform(mask)\n",
    "  mask = torch.squeeze(mask, 0)\n",
    "  mask = mask.to(device, dtype=torch.long)\n",
    "  mask = mask.float()\n",
    "  return mask.cpu().numpy()\n",
    "\n",
    "def create_histogram(confidence, region, species):\n",
    "\n",
    "  # list of bins\n",
    "  bins = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "  plt.hist(confidence, bins=bins, edgecolor='black')\n",
    "\n",
    "  if species == None:\n",
    "    plt.title(region  + ', Image Count - ' + str(len(confidence)))\n",
    "  else:\n",
    "    plt.title(region + ' - ' + species + ', Image Count - ' + str(len(confidence)))\n",
    "\n",
    "  # plotting labelled histogram\n",
    "  plt.xlabel('Model Confidence')\n",
    "  plt.ylabel('Image Count')\n",
    "  plt.show()\n",
    "\n",
    "def generate(region):\n",
    "  region_species = []\n",
    "  for i in inhouse_trained_samples:\n",
    "    if i.startswith(region):\n",
    "      region_species.append(os.path.basename(i).split('_')[1].upper())\n",
    "\n",
    "  region_species = list(set(region_species))\n",
    "  region_main_list = region_rand_list(region, region_species)\n",
    "  region_confidence_list = model_confidence(region_main_list, download = True)\n",
    "  create_histogram(region_confidence_list, region, species = None)\n",
    "\n",
    "def region_rand_list(region, species_list, my_bucket = s3.Bucket('treetracker-training-images')):\n",
    "  main_list = []\n",
    "  for i in species_list:\n",
    "    sample_objects = my_bucket.objects.filter(Prefix= region + '/' + i + '/')\n",
    "    sample_list = [i.key for i in sample_objects]\n",
    "    if len(sample_list) < 100:\n",
    "      main_list.extend(sample_list)\n",
    "    else:\n",
    "      main_list.extend(random.sample(sample_list, 100))\n",
    "\n",
    "  return main_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86255708-c014-41ce-8fe1-ab6b2d13ada6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /teamspace/studios/this_studio/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13.6M/13.6M [00:00<00:00, 210MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume model from /teamspace/studios/this_studio/Deeplab/saved_models/best_deeplabv3plus_mobilenet_custom_os16_0.7854892764326529.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): DeepLabV3(\n",
       "    (backbone): IntermediateLayerGetter(\n",
       "      (low_level_features): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(24, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(24, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (high_level_features): Sequential(\n",
       "        (4): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (5): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (6): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (7): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (8): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (9): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (10): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (11): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(96, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (12): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(96, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (13): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(96, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (14): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(160, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (15): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(960, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=960, bias=False)\n",
       "              (1): BatchNorm2d(960, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(160, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (16): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(960, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=960, bias=False)\n",
       "              (1): BatchNorm2d(960, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(160, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (17): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(960, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=960, bias=False)\n",
       "              (1): BatchNorm2d(960, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(320, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): DeepLabHeadV3Plus(\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (aspp): ASPP(\n",
       "        (convs): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ASPPConv(\n",
       "            (0): AtrousSeparableConvolution(\n",
       "              (body): Sequential(\n",
       "                (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=320, bias=False)\n",
       "                (1): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): ASPPConv(\n",
       "            (0): AtrousSeparableConvolution(\n",
       "              (body): Sequential(\n",
       "                (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=320, bias=False)\n",
       "                (1): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): ASPPConv(\n",
       "            (0): AtrousSeparableConvolution(\n",
       "              (body): Sequential(\n",
       "                (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=320, bias=False)\n",
       "                (1): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): ASPPPooling(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (project): Sequential(\n",
       "          (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (classifier): Sequential(\n",
       "        (0): AtrousSeparableConvolution(\n",
       "          (body): Sequential(\n",
       "            (0): Conv2d(304, 304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=304, bias=False)\n",
       "            (1): Conv2d(304, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model(inhouse_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85e9acc8-1206-4670-8eea-4c73b5307258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_confidence(image_files, download = True, my_bucket = s3.Bucket('treetracker-training-images'), save_binary_mask = False, save_overlayed_mask = False, save_binary_to = '/content/', save_overlayed_to = '/content/'):\n",
    "  metrics = BinarySegMetrics()\n",
    "  # Denormalising samples for generating overlayed masks\n",
    "  denorm = utils.Denormalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "  # refer to the function\n",
    "  load_model(inhouse_default)\n",
    "\n",
    "  confidence = []\n",
    "  foreground = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    model = load_model(inhouse_default).eval()\n",
    "    for img_path in tqdm(image_files):\n",
    "      try:\n",
    "        if download:\n",
    "          my_bucket.download_file(img_path, '/content/test.jpg')\n",
    "          img = Image.open('/content/test.jpg').convert('RGB')\n",
    "        else:\n",
    "          img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        ext = os.path.basename(img_path).split('.')[-1]\n",
    "        img_name = os.path.basename(img_path)[:-len(ext)-1]\n",
    "        # binary masks are named as\n",
    "        path_to_samples = img_path[:len(img_path) - len(ext) - len(img_name) - 2]\n",
    "        path_to_masks = path_to_samples[:len(path_to_samples) - (len(os.path.basename(path_to_samples)))]\n",
    "        mask_path = path_to_masks + 'binary_masks/' + img_name + '_binarymask.' + ext\n",
    "\n",
    "        img = img_transform(img).unsqueeze(0)\n",
    "        img = img.to(device, dtype=torch.float32)\n",
    "        output = model(img)\n",
    "        img = img[0].detach().cpu().numpy()\n",
    "        img = (denorm(img) * 255).transpose(1, 2, 0).astype(np.uint8) # for generating overlayed masks\n",
    "\n",
    "        output = torch.squeeze(output, dim=1)\n",
    "        prob = torch.sigmoid(output).detach()\n",
    "\n",
    "        pred = (prob > 0.5).long().cpu().numpy()\n",
    "        pred = pred[0]\n",
    "        prob = prob[0]\n",
    "\n",
    "        prob = prob.numpy()\n",
    "\n",
    "        count, sum = 0, 0\n",
    "        for i in range(len(prob)):\n",
    "          for j in range(len(prob[1])):\n",
    "            if prob[i][j] > 0.5:\n",
    "              sum += prob[i][j]\n",
    "              count += 1\n",
    "\n",
    "\n",
    "\n",
    "        if os.path.isfile(mask_path):\n",
    "          metrics.update(get_target(mask_path), pred)\n",
    "          score = metrics.get_results()\n",
    "          foreground.append(score['IoU Foreground'])\n",
    "\n",
    "\n",
    "        if save_binary_mask:\n",
    "          pred_rgb = np.array(decode_target(pred)).astype(np.uint8)\n",
    "          pred_image = Image.fromarray(pred_rgb).convert('RGB')\n",
    "          pred_image.save(save_binary_to + img_name + '_binarymask.jpg')\n",
    "\n",
    "        if save_overlayed_mask:\n",
    "          fig = plt.figure()\n",
    "          plt.imshow(img)\n",
    "          plt.axis('off')\n",
    "          plt.imshow(pred, alpha=0.7)\n",
    "          ax = plt.gca()\n",
    "          ax.xaxis.set_major_locator(matplotlib.ticker.NullLocator())\n",
    "          ax.yaxis.set_major_locator(matplotlib.ticker.NullLocator())\n",
    "          plt.savefig(save_overlayed_to + img_name + '_overlayed.jpg', bbox_inches='tight', pad_inches=0)\n",
    "          plt.close()\n",
    "\n",
    "        if count == 0:\n",
    "          confidence.append(0)\n",
    "        else:\n",
    "          confidence.append(sum/count)\n",
    "\n",
    "      except Exception as ex:\n",
    "        '''\n",
    "        template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "        message = template.format(type(ex).__name__, ex.args)\n",
    "        print(message)\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "  if len(foreground) == len(confidence):\n",
    "    return (confidence,foreground)\n",
    "  else:\n",
    "    return confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0c30c04-b2ea-4320-a794-3bb16a93f261",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = ['/teamspace/studios/this_studio/2021.02.01.15.36.01_25.307944666666664_81.02299233333332_65b412b4-571f-4f7d-9870-e8411a0f50db_IMG_20210201_131655_4942076793013214474.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ebf6026-6cd7-4583-b6e7-93a5af8638c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Resume model from /teamspace/studios/this_studio/Deeplab/saved_models/best_deeplabv3plus_mobilenet_custom_os16_0.7854892764326529.pth\n",
      "Device: cpu\n",
      "Resume model from /teamspace/studios/this_studio/Deeplab/saved_models/best_deeplabv3plus_mobilenet_custom_os16_0.7854892764326529.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8257434538901477]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_confidence(image_files, download = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87abef52-34b6-4c4c-b466-a13c69e27a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(region, species, threshold_range, image_count, download = True, my_bucket = s3.Bucket('treetracker-training-images'), save_binary_mask = False, save_overlayed_mask = False, save_binary_to = '/content/', save_overlayed_to = '/content/'):\n",
    "  metrics = BinarySegMetrics()\n",
    "  # Denormalising samples for generating overlayed masks\n",
    "  denorm = utils.Denormalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "  # refer to the function\n",
    "  load_model(inhouse_default)\n",
    "  confidence = []\n",
    "  foreground = []\n",
    "  current_count = 0\n",
    "  img_list = []\n",
    "\n",
    "  if species == None:\n",
    "    region_species = get_species_list(region)\n",
    "    for specie in region_species:\n",
    "      sample_objects = my_bucket.objects.filter(Prefix= region + '/' + specie + '/')\n",
    "      img_list.extend([i.key for i in sample_objects])\n",
    "  else:\n",
    "      sample_objects = my_bucket.objects.filter(Prefix= region + '/' + species + '/')\n",
    "      img_list.extend([i.key for i in sample_objects])\n",
    "\n",
    "\n",
    "  with torch.no_grad():\n",
    "    model = load_model(inhouse_default).eval()\n",
    "    while current_count<image_count:\n",
    "      try:\n",
    "        if download:\n",
    "          r = random.randint(1,len(img_list)-1)\n",
    "\n",
    "          my_bucket.download_file(img_list[r], '/content/test.jpg')\n",
    "          img = Image.open('/content/test.jpg').convert('RGB')\n",
    "        else:\n",
    "          img = Image.open(img_list[r]).convert('RGB')\n",
    "        img = img_transform(img).unsqueeze(0)\n",
    "        img = img.to(device, dtype=torch.float32)\n",
    "        output = model(img)\n",
    "        img = img[0].detach().cpu().numpy()\n",
    "        img = (denorm(img) * 255).transpose(1, 2, 0).astype(np.uint8) # for generating overlayed masks\n",
    "\n",
    "        output = torch.squeeze(output, dim=1)\n",
    "        prob = torch.sigmoid(output).detach()\n",
    "\n",
    "        pred = (prob > 0.5).long().cpu().numpy()\n",
    "        pred = pred[0]\n",
    "        prob = prob[0]\n",
    "\n",
    "        prob = prob.numpy()\n",
    "\n",
    "        count, sum = 0, 0\n",
    "        for i in range(len(prob)):\n",
    "          for j in range(len(prob[1])):\n",
    "            if prob[i][j] > 0.5:\n",
    "              sum += prob[i][j]\n",
    "              count += 1\n",
    "\n",
    "        if count == 0: # no pixel was included in the foreground\n",
    "            pass\n",
    "        else:\n",
    "            if sum/count >= threshold_range[0] and sum/count <= threshold_range[1]:\n",
    "              print('Confidence is ' + str(sum/count))\n",
    "              show('/content/test.jpg')\n",
    "\n",
    "              fig = plt.figure()\n",
    "              plt.imshow(img)\n",
    "              plt.axis('off')\n",
    "              plt.imshow(pred, alpha=0.7)\n",
    "              ax = plt.gca()\n",
    "              ax.xaxis.set_major_locator(matplotlib.ticker.NullLocator())\n",
    "              ax.yaxis.set_major_locator(matplotlib.ticker.NullLocator())\n",
    "              plt.savefig( '/content/test_overlayed.jpg', bbox_inches='tight', pad_inches=0)\n",
    "              plt.close()\n",
    "\n",
    "              show('/content/test_overlayed.jpg')\n",
    "\n",
    "              current_count +=1\n",
    "\n",
    "      except:\n",
    "        pass\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
